---
title: ''
output:
  pdf_document: default
  html_document: default
---


 
```{r, echo=FALSE, message=FALSE}
# Load your libraries here

library('lehmansociology')

load(paste("~","data/RMS_Titanic.Rda", sep="/"))

#Uncomment if you never added labels
#RMS_TItanic$Survival2 <- RMS_Titanic$Survival
#RMS_Titanic$Survival <- as.factor(RMS_Titanic$Survival)
#RMS_Titanic$Survival <- ifelse(RMS_Titanic$Survival == "0", "Died", "Survived")
#RMS_Titanic$SGender <- as.factor(RMS_Titanic$Gender)
#RMS_Titanic$Gender <- ifelse(RMS_Titanic$Gender == "0", "Male", "Female")
#RMS_Titanic$Crew<- ifelse(RMS_Titanic$Crew == 1, "Crew", "Passenger")

#Uncomment if you already added labels to Survival
#RMS_Titanic$Survival2 <- ifelse(RMS_Titanic$Survival == "Died", 0, 1)

```


First let's look at the frequency of survival as a frequency table
and as a crosstab with just a row variable.
Notice that in the first we are using the version with nice labels.

```{r}
frequency(RMS_Titanic$Survival)
```
```{r}
crosstab(Survival ~1, data = RMS_Titanic)
```

If you knew nothing but this, and you had to predict a certain passenger
would survive or die, what would you predict?  Why?

What percent of the time would your prediction be wrong?


Now we are going to use a special function called the "logit" function on 
the probability of survival from our frequency table.


```{r}
logit(.3225)
```

Now we will look at the same thing in a "linear model" format.

```{r}
# This is a generalized linear model with just an intercept, no independent variable
results<-glm(Survival2 ~ 1, data=RMS_Titanic, family = binomial(link = logit))

coefficients<-coef(results)
coefficients
```
What do you notice about the relationship between the coefficients and 
the calculations earlier?

In math, a lot of times the term inverse means to undo something.
For example 1/3 is the inverse of 3. If you multiply somethingby
1/3 and then by 3 you end up with the original value.

Let's get the inverse logit.
```{r}
inverselogit(coefficients)

```
How does the inverse logit relate to what we did earlier? 


The inverse logit is the *predicted probability* of surviving.

Now let's try adding an independent variable.

```{r}
crosstab(Survival2 ~ Gender, data = RMS_Titanic, format = "col_percent")
```

If you knew nothing else but this cross tab, would you predict that
a female would survive or die?  Why?



If you knew nothing else, would you predict that a male would survive or die
Why?


What percentage of the time would you be wrong for females?

What percentage of the time would you be wrong for males?

Are these percentages higher or lower than that for frequency 
without the independent variable?




Now let's take the logits for the two separate predictions. Keep in mind
that we are rounding.

```{r}
# Female
logit(.733)

# Male
logit(.207)
```

Why is the Male logit negative and the female one positive?


Now let's run our linear model with Gender as an independent variable.

```{r}
#
results<-glm(Survival2 ~ Gender, data=RMS_Titanic, family = binomial(link = logit))
coef(results)
```

Notice that now we have two coefficients.  
The coefficient for GenderMale represents the impact of being male
compared to the "excluded" or other group, the females in this case.

Why is the coefficient for GenderMale negative?


Male estimate = Intercept + 1*GenderMale
```{r}
1.01 + 1*(-2.35)
```
Female estimate = Intercept + 0 * GenderMale = Intercept 
```{r}
1.01 + 0*(-2.35)
```

How do these estimates relate to the logits we calculated for the cross tab?
(Assume a little bit of rounding error is expected)

Intercept represents the females. Why is this?


Now let's calculate the inverse logits.

```{r}
inverselogit(1.01)
inverselogit(1.01 + -2.35)

```
How do these relate to our cross tabs?

By the way, we don't need to do the calculations by hand, we can 
get the predicted probability for each observation from R.

```{r}
table(results$linear.predictors)
table(fitted.values(results))
```



The inverse logit is the *predicted probability* of surviving, accounting
for gender.

Overall the glm is a way of summarizing crosstabs by using
a linear equation.

It might seem more complicated but we will see that when you start having 
many independent variables it actually becomes simpler to understand.

Before doing that let's repeat the same analysis for Crew.

```{r}
crosstab(Survival ~ Crew, data = RMS_Titanic, format = "col_percent")
```
```{r}
results<-glm(Survival2 ~ Crew, data=RMS_Titanic, family = binomial(link = logit))
coef(results)
table(fitted.values(results))
```

Explain how the cross tabs relate to the fitted values.

How are the fitted values calculated for someone who is a passenger?

How are the fitted values calculated for someone who is a crew member?

